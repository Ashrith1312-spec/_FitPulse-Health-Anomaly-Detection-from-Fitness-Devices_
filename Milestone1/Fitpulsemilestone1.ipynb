{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone 1: Fitness Data Preprocessing and Normalization"
      ],
      "metadata": {
        "id": "BhKuxqCN9Y1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective:\n",
        "The goal of this notebook is to ingest raw fitness tracker data (CSV files), validate schemas, and normalize the data into a clean, consolidated format for analysis.\n",
        "\n",
        "# Key Tasks:\n",
        "\n",
        "Ingest: Read CSV files for Sleep, Steps, and Heart Rate.\n",
        "\n",
        "Validate: Ensure column names and data types are consistent.\n",
        "\n",
        "Normalize: Convert all timestamps to UTC.\n",
        "\n",
        "Align: Resample disparate data frequencies to a uniform 1-minute interval.\n",
        "\n",
        "Clean: Handle missing values and generate a final output file."
      ],
      "metadata": {
        "id": "NXoBxyF79e0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Imports and Setup\n",
        "First, we import the necessary libraries and load the raw dataset. We will also perform an initial inspection to understand the data structure."
      ],
      "metadata": {
        "id": "1ieAr9Jc_n75"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWlNOo3zxxEF",
        "outputId": "4cb6d98e-59d0-4495-ea96-0b562c78e60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Display settings to ensure we can see all columns during inspection\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"Libraries loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion & Schema Validation\n"
      ],
      "metadata": {
        "id": "hOufZz-1Aaly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 1: Ingesting Data ---\")\n",
        "\n",
        "try:\n",
        "    # Load the datasets with low_memory=False to handle mixed types efficiently\n",
        "    sleep_df = pd.read_csv(\"/content/minuteSleep_merged.csv\", low_memory=False)\n",
        "    steps_df = pd.read_csv(\"/content/minuteStepsNarrow_merged.csv\", low_memory=False)\n",
        "    hr_df = pd.read_csv(\"/content/heartrate_seconds_merged.csv\", on_bad_lines=\"skip\", low_memory=False)\n",
        "\n",
        "    # 1. Standardize Column Names\n",
        "    # We map dataset-specific time columns to a generic 'Time' column\n",
        "    sleep_df = sleep_df.rename(columns={\"date\": \"Time\", \"value\": \"Sleep\"})\n",
        "    steps_df = steps_df.rename(columns={\"ActivityMinute\": \"Time\"})\n",
        "    hr_df = hr_df.rename(columns={\"Value\": \"HeartRate\"})\n",
        "\n",
        "    # 2. Enforce Data Types\n",
        "    # IDs must be strings to prevent numerical errors during merging\n",
        "    for df in [sleep_df, steps_df, hr_df]:\n",
        "        df[\"Id\"] = df[\"Id\"].astype(str)\n",
        "\n",
        "    print(\" Datasets loaded and schema standardized.\")\n",
        "    print(f\"  - Sleep Data Shape: {sleep_df.shape}\")\n",
        "    print(f\"  - Steps Data Shape: {steps_df.shape}\")\n",
        "    print(f\"  - Heart Rate Data Shape: {hr_df.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\" Error: One or more files are missing.\")\n",
        "    print(\"Please ensure 'minuteSleep_merged.csv', 'minuteStepsNarrow_merged.csv', and 'heartrate_seconds_merged.csv' are in /content/.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyTGTNF98ZJJ",
        "outputId": "c5a7d2b6-ebd8-417c-f0ad-e302c01dc1df"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Ingesting Data ---\n",
            " Datasets loaded and schema standardized.\n",
            "  - Sleep Data Shape: (188521, 4)\n",
            "  - Steps Data Shape: (1445040, 3)\n",
            "  - Heart Rate Data Shape: (2483658, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing Aggregation\n"
      ],
      "metadata": {
        "id": "YPvulvRZAmgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 2: Aggregating to 1-Minute Intervals ---\")\n",
        "\n",
        "# We specify the format explicitly to fix the warning and speed up processing\n",
        "# Format: Month/Day/Year Hour:Minute:Second AM/PM\n",
        "date_fmt = \"%m/%d/%Y %I:%M:%S %p\"\n",
        "\n",
        "# Convert Time columns to datetime objects using the format\n",
        "sleep_df[\"Time\"] = pd.to_datetime(sleep_df[\"Time\"], format=date_fmt, errors=\"coerce\")\n",
        "steps_df[\"Time\"] = pd.to_datetime(steps_df[\"Time\"], format=date_fmt, errors=\"coerce\")\n",
        "\n",
        "# For Heart Rate, we parse then floor to the nearest minute\n",
        "hr_df[\"Time\"] = pd.to_datetime(hr_df[\"Time\"], format=date_fmt, errors=\"coerce\").dt.floor(\"min\")\n",
        "\n",
        "# Drop rows where Time conversion might have failed\n",
        "sleep_df = sleep_df.dropna(subset=[\"Time\"])\n",
        "steps_df = steps_df.dropna(subset=[\"Time\"])\n",
        "hr_df = hr_df.dropna(subset=[\"Time\"])\n",
        "\n",
        "# Group by ID and Time to handle duplicates (Aggregation)\n",
        "steps_agg = steps_df.groupby([\"Id\", \"Time\"], as_index=False)[\"Steps\"].sum()\n",
        "sleep_agg = sleep_df.groupby([\"Id\", \"Time\"], as_index=False)[\"Sleep\"].max()\n",
        "hr_agg = hr_df.groupby([\"Id\", \"Time\"], as_index=False)[\"HeartRate\"].mean()\n",
        "\n",
        "print(\"✓ Data aggregated successfully.\")\n",
        "print(f\"  - Aggregated HR Shape: {hr_agg.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p_Q5qZ98bzn",
        "outputId": "b0c0deee-aa95-48b4-c554-f9b896b308e6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 2: Aggregating to 1-Minute Intervals ---\n",
            "✓ Data aggregated successfully.\n",
            "  - Aggregated HR Shape: (333420, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging & Normalization\n"
      ],
      "metadata": {
        "id": "vh54FRboA6Kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 3: Merging & UTC Normalization ---\")\n",
        "\n",
        "# Merge Steps and Sleep first\n",
        "merged_temp = steps_agg.merge(sleep_agg, on=[\"Id\", \"Time\"], how=\"inner\")\n",
        "\n",
        "# Merge the result with Heart Rate\n",
        "merged_df = merged_temp.merge(hr_agg, on=[\"Id\", \"Time\"], how=\"inner\")\n",
        "\n",
        "# Normalize to UTC\n",
        "merged_df[\"Time\"] = pd.to_datetime(merged_df[\"Time\"], utc=True)\n",
        "\n",
        "print(f\"✓ Data merged. Combined Shape: {merged_df.shape}\")\n",
        "print(f\"  - Date Range: {merged_df['Time'].min()} to {merged_df['Time'].max()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOsH8Tc48gPM",
        "outputId": "57107c8a-d2a9-4b1d-fa23-7b84b7727188"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 3: Merging & UTC Normalization ---\n",
            "✓ Data merged. Combined Shape: (1095, 5)\n",
            "  - Date Range: 2016-04-12 00:00:00+00:00 to 2016-04-12 09:59:00+00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning (Missing Values & Alignment)\n"
      ],
      "metadata": {
        "id": "UyF_HQ13B5z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 4: Cleaning & Resampling ---\")\n",
        "\n",
        "# 1. Fill NaN values\n",
        "merged_df[\"Steps\"] = pd.to_numeric(merged_df[\"Steps\"], errors=\"coerce\").fillna(0)\n",
        "merged_df[\"Sleep\"] = pd.to_numeric(merged_df[\"Sleep\"], errors=\"coerce\").fillna(0)\n",
        "median_hr = merged_df[\"HeartRate\"].median()\n",
        "merged_df[\"HeartRate\"] = pd.to_numeric(merged_df[\"HeartRate\"], errors=\"coerce\").fillna(median_hr)\n",
        "\n",
        "# 2. Resample to ensure continuous 1-minute intervals\n",
        "# Set Index for resampling\n",
        "merged_df = merged_df.set_index(\"Time\")\n",
        "\n",
        "# Resample by ID\n",
        "final_df = merged_df.groupby(\"Id\").resample(\"1min\").agg({\n",
        "    \"Steps\": \"sum\",\n",
        "    \"Sleep\": \"max\",\n",
        "    \"HeartRate\": \"mean\"\n",
        "})\n",
        "\n",
        "# Resampling creates NaNs for the new time slots (gaps), fill them again\n",
        "final_df[\"Steps\"] = final_df[\"Steps\"].fillna(0)\n",
        "final_df[\"Sleep\"] = final_df[\"Sleep\"].fillna(0)\n",
        "final_df[\"HeartRate\"] = final_df[\"HeartRate\"].fillna(median_hr)\n",
        "\n",
        "# Reset index to restore columns\n",
        "final_df = final_df.reset_index()\n",
        "\n",
        "print(\"✓ Data cleaned and realigned to 1-minute intervals.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpgY6jwu8i6k",
        "outputId": "70ac5a1c-c2d1-491c-f2b5-93da9a13662f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 4: Cleaning & Resampling ---\n",
            "✓ Data cleaned and realigned to 1-minute intervals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Output"
      ],
      "metadata": {
        "id": "qvKuVEi1IOYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 5: Final Output ---\")\n",
        "\n",
        "# Sort for better readability\n",
        "final_df = final_df.sort_values([\"Id\", \"Time\"])\n",
        "\n",
        "# Save to CSV\n",
        "output_path = \"/content/fitbit_clean_final.csv\"\n",
        "final_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"✓ Success! File saved to: {output_path}\")\n",
        "print(\"\\nFirst 5 rows of clean data:\")\n",
        "print(final_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1mTfTJWIQ_y",
        "outputId": "e6648d31-fee0-4c48-a862-ff2ccd48147f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 5: Final Output ---\n",
            "✓ Success! File saved to: /content/fitbit_clean_final.csv\n",
            "\n",
            "First 5 rows of clean data:\n",
            "           Id                      Time  Steps  Sleep  HeartRate\n",
            "0  4020332650 2016-04-12 00:00:00+00:00      0    1.0  63.500000\n",
            "1  4020332650 2016-04-12 00:01:00+00:00      0    1.0  65.913043\n",
            "2  4020332650 2016-04-12 00:02:00+00:00      0    1.0  67.000000\n",
            "3  4020332650 2016-04-12 00:03:00+00:00      0    1.0  67.000000\n",
            "4  4020332650 2016-04-12 00:04:00+00:00      0    1.0  67.000000\n"
          ]
        }
      ]
    }
  ]
}